{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgdkjVf_oB8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06058c52-ea78-41f9-e62e-44ebd324cd0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaYxfGHveC2e"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tmjbD8IWI0u"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset=pd.read_csv('/content/drive/MyDrive/adu (1).csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmvowkcWV49I"
      },
      "source": [
        "#ULTIMATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNgDTB69Odxj"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otueGdYQUDYV"
      },
      "source": [
        "Chuyển câu văn về kiểu gõ telex khi không bật Unikey"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html(txt):\n",
        "    return re.sub(r\"http\\S+\", \"\", txt)"
      ],
      "metadata": {
        "id": "cCPGowHu2AHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x5-4pmiUEjk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bde4b149-def8-42a4-f45e-2d3548713ebf"
      },
      "source": [
        "\"\"\"\n",
        "    Start section: Chuyển câu văn về kiểu gõ telex khi không bật Unikey\n",
        "    Ví dụ: thủy = thuyr, tượng = tuwowngj\n",
        "\"\"\"\n",
        "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
        "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
        "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
        "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
        "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
        "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
        "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
        "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
        "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
        "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
        "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
        "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
        "\n",
        "nguyen_am_to_ids = {}\n",
        "\n",
        "for i in range(len(bang_nguyen_am)):\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
        "\n",
        "\n",
        "def vn_word_to_telex_type(word):\n",
        "    dau_cau = 0\n",
        "    new_word = ''\n",
        "    for char in word:\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            new_word += char\n",
        "            continue\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "        new_word += bang_nguyen_am[x][-1]\n",
        "    new_word += bang_ky_tu_dau[dau_cau]\n",
        "    return new_word\n",
        "\n",
        "\n",
        "def vn_sentence_to_telex_type(sentence):\n",
        "    \"\"\"\n",
        "    Chuyển câu tiếng việt có dấu về kiểu gõ telex.\n",
        "    :param sentence:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        words[index] = vn_word_to_telex_type(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    End section: Chuyển câu văn về kiểu gõ telex khi không bật Unikey\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    End section: Chuyển câu văn về kiểu gõ telex khi không bật Unikey\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vn_word_to_telex_type('gà')"
      ],
      "metadata": {
        "id": "R8fRLySjpbAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec5901d7-85a1-4077-d36d-0a8833eeb789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gaf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNG-qc3tRF3Z"
      },
      "source": [
        "# **Chuẩn hoá unicode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr_EHfVoRUex"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import regex as re\n",
        "\n",
        "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
        "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
        "\n",
        "\n",
        "def loaddicchar():\n",
        "    dic = {}\n",
        "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
        "        '|')\n",
        "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
        "        '|')\n",
        "    for i in range(len(char1252)):\n",
        "        dic[char1252[i]] = charutf8[i]\n",
        "    return dic\n",
        "\n",
        "\n",
        "dicchar = loaddicchar()\n",
        "\n",
        "\n",
        "def convert_unicode(txt):\n",
        "    return re.sub(\n",
        "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
        "        lambda x: dicchar[x.group()], txt)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8BMFB0kUNsu"
      },
      "source": [
        "Dùng òa úy thay oà uý"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjJPkrKgUOwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0d1c88-4e97-4c99-fdc3-e9487fea4c95"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "    Start section: Chuyển câu văn về cách gõ dấu kiểu cũ: dùng òa úy thay oà uý\n",
        "    Xem tại đây:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\n",
        "    if not is_valid_vietnam_word(word):\n",
        "        return word\n",
        "\n",
        "    chars = list(word)\n",
        "    dau_cau = 0\n",
        "    nguyen_am_index = []\n",
        "    qu_or_gi = False\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            continue\n",
        "        elif x == 9:  # check qu\n",
        "            if index != 0 and chars[index - 1] == 'q':\n",
        "                chars[index] = 'u'\n",
        "                qu_or_gi = True\n",
        "        elif x == 5:  # check gi\n",
        "            if index != 0 and chars[index - 1] == 'g':\n",
        "                chars[index] = 'i'\n",
        "                qu_or_gi = True\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "            chars[index] = bang_nguyen_am[x][0]\n",
        "        if not qu_or_gi or index != 1:\n",
        "            nguyen_am_index.append(index)\n",
        "    if len(nguyen_am_index) < 2:\n",
        "        if qu_or_gi:\n",
        "            if len(chars) == 2:\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
        "            else:\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
        "                if x != -1:\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
        "                else:\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
        "            return ''.join(chars)\n",
        "        return word\n",
        "\n",
        "    for index in nguyen_am_index:\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\n",
        "        if x == 4 or x == 8:  # ê, ơ\n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
        "            # for index2 in nguyen_am_index:\n",
        "            #     if index2 != index:\n",
        "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
        "            #         chars[index2] = bang_nguyen_am[x][0]\n",
        "            return ''.join(chars)\n",
        "\n",
        "    if len(nguyen_am_index) == 2:\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
        "        else:\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    else:\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
        "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
        "    return ''.join(chars)\n",
        "\n",
        "\n",
        "def is_valid_vietnam_word(word):\n",
        "    chars = list(word)\n",
        "    nguyen_am_index = -1\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x != -1:\n",
        "            if nguyen_am_index == -1:\n",
        "                nguyen_am_index = index\n",
        "            else:\n",
        "                if index - nguyen_am_index != 1:\n",
        "                    return False\n",
        "                nguyen_am_index = index\n",
        "    return True\n",
        "\n",
        "\n",
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
        "    \"\"\"\n",
        "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
        "        # print(cw)\n",
        "        if len(cw) == 3:\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
        "        words[index] = ''.join(cw)\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    End section: Chuyển câu văn về cách gõ dấu kiểu cũ: dùng òa úy thay oà uý\n",
        "    Xem tại đây: https://vi.wikipedia.org/wiki/Quy_tắc_đặt_dấu_thanh_trong_chữ_quốc_ngữ\n",
        "\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    print(chuan_hoa_dau_cau_tieng_viet('anh hoà, đang làm.. gìau'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anh hòa, đang làm.. giàu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7gXpXMuVnY_"
      },
      "source": [
        "Loại bỏ ký tự cố tính viết dài trong câu:\n",
        "\n",
        "eg: đâyyyyyyyyyy -> đây"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOKJRUGXXiwU"
      },
      "source": [
        "# lấy dữ liệu cho teencode\n",
        "import pandas as pd\n",
        "teencode_df = pd.read_csv('/content/drive/MyDrive/Textual data/teencode.txt',names=['teencode','map'],sep='\\t',)\n",
        "teencode_list = teencode_df['teencode'].to_list()\n",
        "map_list = teencode_df['map'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzP1ndUSOiyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1e81c4-3324-4985-c1af-75ce1df99282"
      },
      "source": [
        "# Nltk for connect sent\n",
        "import nltk\n",
        "nltk.download('perluniprops')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YkhCqGL2oB8",
        "outputId": "1ba744ec-4323-4253-a5b1-16d58f63d944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import words\n",
        "\n",
        "english_word_set = set(words.words())\n",
        "\n",
        "def is_english_word(word):\n",
        "    return word.lower() in english_word_set\n",
        "print(is_english_word(\"hello\"))  # True\n",
        "print(is_english_word(\"tộc\"))    # False\n"
      ],
      "metadata": {
        "id": "GBIzKx8sYVQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b03f3f-4449-42bd-a9dc-a4943d1f9aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtchyroHIsAj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ffa7b07f-075c-4ecd-9af6-fa7a2000c466"
      },
      "source": [
        "sent = 'hello, cute vcllll tộc ttrưởng đi đâu chơi đấyyyyyy. Đc cc, được luôn. Hahahahahahaaaaaaaaaaaaaaaa ?'\n",
        "\n",
        "def remove_dub_char(sentence):\n",
        "    sentence = str(sentence)\n",
        "    words = []\n",
        "    for word in sentence.strip().split():\n",
        "        if word in teencode_list:\n",
        "            words.append(word)\n",
        "            continue\n",
        "        if is_english_word(word) == True:\n",
        "            words.append(word)\n",
        "            continue\n",
        "        else: words.append(re.sub(r'([A-Z])\\1+', lambda m: m.group(1), word, flags=re.IGNORECASE))\n",
        "    return ' '.join(words)\n",
        "\n",
        "remove_dub_char(sent)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'helo, cute vcl tộc trưởng đi đâu chơi đấy. Đc c, được luôn. Hahahahahaha ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wti4h-oUxSx"
      },
      "source": [
        "Tách từ tiếng Việt\n",
        "\n",
        "Học sinh học sinh học ⇒ Học_sinh học sinh_học"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7hgkCT_vDpE"
      },
      "source": [
        "link_count = 0\n",
        "unicode_count = 0\n",
        "dau_count = 0\n",
        "lower_count = 0\n",
        "noneed_count = 0\n",
        "space_count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LOK9e25VuPX"
      },
      "source": [
        "def text_preprocess(document):\n",
        "    global link_count\n",
        "    global unicode_count\n",
        "    global dau_count\n",
        "    global lower_count\n",
        "    global noneed_count\n",
        "    global space_count\n",
        "\n",
        "    document = str(document)\n",
        "\n",
        "    # đưa về lower\n",
        "    ducument_before_lower = document\n",
        "    document = document.lower()\n",
        "    if ducument_before_lower != document:\n",
        "      # print(\"Cau chua xu ly:\", ducument_before_lower)\n",
        "      # print(\"Cau da xu ly:\", document)\n",
        "      lower_count += 1\n",
        "    # del document1\n",
        "\n",
        "    # xóa khoảng trắng thừa\n",
        "    ducument_before_space = document\n",
        "    document = re.sub(r'\\s+', ' ', document).strip()\n",
        "    if ducument_before_space != document:\n",
        "      # print(\"Cau chua xu ly:\", ducument_before_space)\n",
        "      # print(\"Cau da xu ly:\", document)\n",
        "      space_count += 1\n",
        "    # del document1\n",
        "\n",
        "      # print(\"Cau chua xu ly:\", ducument_before_html)\n",
        "      # print(\"Cau da xu ly:\", document)\n",
        "      link_count += 1\n",
        "    # del document1\n",
        "\n",
        "    # chuẩn hóa unicode\n",
        "    ducument_before_unicode = document\n",
        "    document = convert_unicode(document)\n",
        "    if ducument_before_unicode != document:\n",
        "      unicode_count += 1\n",
        "    # del document1\n",
        "\n",
        "    # xóa các ký tự không cần thiết\n",
        "    #ducument_before_redundant = document\n",
        "    #document = remove_dub_char(document)\n",
        "    #if ducument_before_redundant != document:\n",
        "      # print(\"Cau chua xu ly:\", ducument_before_redundant)\n",
        "      # print(\"Cau da xu ly:\", document)\n",
        "      #noneed_count += 1\n",
        "    # del document1\n",
        "\n",
        "\n",
        "    # chuẩn hóa cách gõ dấu tiếng Việt\n",
        "    ducument_before_dau = document\n",
        "    document = chuan_hoa_dau_cau_tieng_viet(document)\n",
        "    if ducument_before_dau != document:\n",
        "      print(\"Cau chua xu ly:\", ducument_before_dau)\n",
        "      print(\"Cau da xu ly:\", document)\n",
        "      dau_count += 1\n",
        "    # del document1\n",
        "\n",
        "    return document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPBjgWJtts3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "afd95d70-422c-47ce-a480-386f0273c309"
      },
      "source": [
        "text_preprocess('Anh thích ăn cơm heheeee')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anh thích ăn cơm heheeee'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVIIBGL6uUVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e538233-14e1-46ad-fad8-c9f106061a0c"
      },
      "source": [
        "'hoà thuận' == 'hòa thuận'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYwwNVpAd2PE"
      },
      "source": [
        "#DO IT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqr8Je3NVowX"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/datasetprimary - Sheet1 (2).csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adfs_BbveIDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f48417d-7dd8-4ec4-efaa-6e180b5c69c6"
      },
      "source": [
        "link_count = 0\n",
        "unicode_count = 0\n",
        "dau_count = 0\n",
        "lower_count = 0\n",
        "noneed_count = 0\n",
        "space_count = 0\n",
        "train['vi_review'] = train['vi_review'].apply(lambda x:text_preprocess(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cau chua xu ly: êu ơi hay quáaaaa\n",
            "Cau da xu ly: êu ơi hay quaáaaa\n",
            "Cau chua xu ly: 21/06/2020\n",
            "Cau da xu ly: 21062020\n",
            "Cau chua xu ly: 12/09 nè\n",
            "Cau da xu ly: 1209 nè\n",
            "Cau chua xu ly: thag thủ môn chắc là thag tệ nhất trong lichk sử đội bóng. bắt tay kém phản xạ chậm. chân lại càng thảm hoạ\n",
            "Cau da xu ly: thag thủ môn chắc là thag tệ nhất trong lichk sử đội bóng. bắt tay kém phản xạ chậm. chân lại càng thảm họa\n",
            "Cau chua xu ly: loại tai nghe gaming được anh em săn đón nhất mùa hè này https://shorten.asia/kdvkpxta tham khảo và cùng tận hưởng nhé\n",
            "Cau da xu ly: loại tai nghe gaming được anh em săn đón nhất mùa hè này https:shorten.asiakdvkpxta tham khảo và cùng tận hưởng nhé\n",
            "Cau chua xu ly: 8/9/2020 vẫn đang nghe\n",
            "Cau da xu ly: 892020 vẫn đang nghe\n",
            "Cau chua xu ly: 18/12/2021 nhẹ nhàng và sâu lắng\n",
            "Cau da xu ly: 18122021 nhẹ nhàng và sâu lắng\n",
            "Cau chua xu ly: các bạn có thể ban phát cho mình 1 like fanpage được không ? bọn mình mong muốn thành lập clb thể thao điện tử nên thực sự cần like. các bạn giúp mình với ! mình cảm ơn các bạn link : http://www.facebook.com/escvnua/\n",
            "Cau da xu ly: các bạn có thể ban phát cho mình 1 like fanpage được không ? bọn mình mong muốn thành lập clb thể thao điện tử nên thực sự cần like. các bạn giúp mình với ! mình cảm ơn các bạn link : http:www.facebook.comescvnua\n",
            "Cau chua xu ly: 5/5/2020\n",
            "Cau da xu ly: 552020\n",
            "Cau chua xu ly: 25/2/2021\n",
            "Cau da xu ly: 2522021\n",
            "Cau chua xu ly: 3 .00 am ngày 5/1/2020 . vừa nghe nhạc vừa ôn thi để qua kỳ thi ở bách khoa nè .\n",
            "Cau da xu ly: 3 .00 am ngày 512020 . vừa nghe nhạc vừa ôn thi để qua kỳ thi ở bách khoa nè .\n",
            "Cau chua xu ly: chúc a sức khoẻ bài này hay và ý nghĩa lắm\n",
            "Cau da xu ly: chúc a sức khỏe bài này hay và ý nghĩa lắm\n",
            "Cau chua xu ly: amrabat đá hay thế nhờ , tiền kiến tạo cho đội bạn ghi bàn luôn haha. quá cháyyyy\n",
            "Cau da xu ly: amrabat đá hay thế nhờ , tiền kiến tạo cho đội bạn ghi bàn luôn haha. quá chaýyyy\n",
            "Cau chua xu ly: ad cho xin link mp3 với ạ , thks @@ nghiện rồiii\n",
            "Cau da xu ly: ad cho xin link mp3 với ạ , thks @@ nghiện rôìii\n",
            "Cau chua xu ly: 3/2/2021- cần thơ\n",
            "Cau da xu ly: 322021- cần thơ\n",
            "Cau chua xu ly: hy vọng sau này tuổi 30 mình sẽ hạnh phúc cùng lkh 28/9/2023 🎉\n",
            "Cau da xu ly: hy vọng sau này tuổi 30 mình sẽ hạnh phúc cùng lkh 2892023 🎉\n",
            "Cau chua xu ly: 17/10/2020. team 9x\n",
            "Cau da xu ly: 17102020. team 9x\n",
            "Cau chua xu ly: 20/5/2021 2006 cafe google thương em nhìu 😘 nhớ em lắm cô gái dễ thương xinh đẹp giờ em ở đâu 🥺\n",
            "Cau da xu ly: 2052021 2006 cafe google thương em nhìu 😘 nhớ em lắm cô gái dễ thương xinh đẹp giờ em ở đâu 🥺\n",
            "Cau chua xu ly: ngày xưa bên nhau vô hồn nhiên và thơ ngây đôi mắt ngày nào nồng ấm rõ đã xa xăm mỗi khi mình bên nhau anh thường hôn lên đôi mắt của em và từ khi em ra đi đôi mắt đó đã không thuộc về anh nữa bh đã là của người khác rồi anh thì vẫn thế vẫn yêu em mãi mãi âm thầm và luôn dõi theo em cho dù em đã bên người khác yêu em suốt đời có phải anh ngốc quá k0 khi cứ ảo tưởng rằng em còn bên anh mãi những tỉnh giấc lại thì hóa ra anh chỉ nằm mơ 3/5/0202\n",
            "Cau da xu ly: ngày xưa bên nhau vô hồn nhiên và thơ ngây đôi mắt ngày nào nồng ấm rõ đã xa xăm mỗi khi mình bên nhau anh thường hôn lên đôi mắt của em và từ khi em ra đi đôi mắt đó đã không thuộc về anh nữa bh đã là của người khác rồi anh thì vẫn thế vẫn yêu em mãi mãi âm thầm và luôn dõi theo em cho dù em đã bên người khác yêu em suốt đời có phải anh ngốc quá k0 khi cứ ảo tưởng rằng em còn bên anh mãi những tỉnh giấc lại thì hóa ra anh chỉ nằm mơ 350202\n",
            "Cau chua xu ly: your music playlist is very good https://www.youtube.com/watch?v=loacel4inxq\n",
            "Cau da xu ly: your music playlist is very good https:www.youtube.comwatch?v=loacel4inxq\n",
            "Cau chua xu ly: 23/2/2021 - đã ghé thăm\n",
            "Cau da xu ly: 2322021 - đã ghé thăm\n",
            "Cau chua xu ly: ko có a trưởng thì may là hoà\n",
            "Cau da xu ly: ko có a trưởng thì may là hòa\n",
            "Cau chua xu ly: 13/8/2020\n",
            "Cau da xu ly: 1382020\n",
            "Cau chua xu ly: 6/1/2021\n",
            "Cau da xu ly: 612021\n",
            "Cau chua xu ly: thời ý nguyễn đức chung là đại uý 😢\n",
            "Cau da xu ly: thời ý nguyễn đức chung là đại úy 😢\n",
            "Cau chua xu ly: qúa hay.\n",
            "Cau da xu ly: quá hay.\n",
            "Cau chua xu ly: 20/11/202\n",
            "Cau da xu ly: 2011202\n",
            "Cau chua xu ly: 3 sọc đỏ nền vàng vẫn mang phong thuỷ không tốt cho các thủ môn mà...từ mùa world cup tới giờ luôn\n",
            "Cau da xu ly: 3 sọc đỏ nền vàng vẫn mang phong thủy không tốt cho các thủ môn mà...từ mùa world cup tới giờ luôn\n",
            "Cau chua xu ly: sài gòn chiều mưa thứ 7 ngày 11/05/2019\n",
            "Cau da xu ly: sài gòn chiều mưa thứ 7 ngày 11052019\n",
            "Cau chua xu ly: nghe những bài tình ca nhẹ nhàng rồi thì cùng nghe những giai điệu tươi vui, rộn ràng về tình yêu nhé ^^ https://www.youtube.com/watch?v=ghaechocwxq\n",
            "Cau da xu ly: nghe những bài tình ca nhẹ nhàng rồi thì cùng nghe những giai điệu tươi vui, rộn ràng về tình yêu nhé ^^ https:www.youtube.comwatch?v=ghaechocwxq\n",
            "Cau chua xu ly: mu bây giờ chỉ là một cái kho điểm khổng lồ mà bất cứ đội nào cũng có thể lấy 3 điểm. nói chung là một cái đội không còn ai sợ nửa. đá thì ngu mà ngôi sao đi hầu toà thì nhiều\n",
            "Cau da xu ly: mu bây giờ chỉ là một cái kho điểm khổng lồ mà bất cứ đội nào cũng có thể lấy 3 điểm. nói chung là một cái đội không còn ai sợ nửa. đá thì ngu mà ngôi sao đi hầu tòa thì nhiều\n",
            "Cau chua xu ly: một buổi trưa hè đầy gió..... nghe thật hay..... \"nghe này ai ơi\" thank you admin =)). #05/05/2019\n",
            "Cau da xu ly: một buổi trưa hè đầy gió..... nghe thật hay..... \"nghe này ai ơi\" thank you admin =)). #05052019\n",
            "Cau chua xu ly: 15/2/2021\n",
            "Cau da xu ly: 1522021\n",
            "Cau chua xu ly: 1/1/2020...\n",
            "Cau da xu ly: 112020...\n",
            "Cau chua xu ly: tưởng nhuộm đỏ trời âu chứ hoá ra là mang nhục ở trời âu à\n",
            "Cau da xu ly: tưởng nhuộm đỏ trời âu chứ hóa ra là mang nhục ở trời âu à\n",
            "Cau chua xu ly: 7/11 nhớ đến wanbi tuấn anh.\n",
            "Cau da xu ly: 711 nhớ đến wanbi tuấn anh.\n",
            "Cau chua xu ly: cám ơn. onana dất nhiều.đặc vụ được phải đến để huỷ diệt tenhag\n",
            "Cau da xu ly: cám ơn. onana dất nhiều.đặc vụ được phải đến để hủy diệt tenhag\n",
            "Cau chua xu ly: làm sao để kiếm 1000$ từ beegroud https://www.youtube.com/watch?v=x8mwtst-fao\n",
            "Cau da xu ly: làm sao để kiếm 1000$ từ beegroud https:www.youtube.comwatch?v=x8mwtst-fao\n",
            "Cau chua xu ly: *hay lắm bạn. cho mình hỏi bạn làm video bằng app gì vậy ạ? mình không biết gọi là gì nhưng tạm gọi là animation lúc đầu đẹp phết. toàn video nhìn cũng hài hoà dễ chịu. đẹp đó bạn!*\n",
            "Cau da xu ly: *hay lắm bạn. cho mình hỏi bạn làm video bằng app gì vậy ạ? mình không biết gọi là gì nhưng tạm gọi là animation lúc đầu đẹp phết. toàn video nhìn cũng hài hòa dễ chịu. đẹp đó bạn!*\n",
            "Cau chua xu ly: hôm nay tớ nghe nhe27/9/2020\n",
            "Cau da xu ly: hôm nay tớ nghe nhe2792020\n",
            "Cau chua xu ly: 8x vẫn cứ là chuẩn nhất... đẹp nhất vẫn là 8x... 29/11/2020\n",
            "Cau da xu ly: 8x vẫn cứ là chuẩn nhất... đẹp nhất vẫn là 8x... 29112020\n",
            "Cau chua xu ly: bao nhiêu mùa giả mu toàn thủ môn giỏii. trừ onana\n",
            "Cau da xu ly: bao nhiêu mùa giả mu toàn thủ môn gioỉi. trừ onana\n",
            "Cau chua xu ly: 10h20 ngày 04/04/2021 8x có ai đang ngồi nghe như mình ko\n",
            "Cau da xu ly: 10h20 ngày 04042021 8x có ai đang ngồi nghe như mình ko\n",
            "Cau chua xu ly: nếu lấy tên dv để phụ hoạ nhân vật thì vai phản diện là phàn thiếu hoàng chứ đâu phải ngô ngạn tổ\n",
            "Cau da xu ly: nếu lấy tên dv để phụ họa nhân vật thì vai phản diện là phàn thiếu hoàng chứ đâu phải ngô ngạn tổ\n",
            "Cau chua xu ly: em đã rời xa anh...chẳng kịp níuuuuuuuuuuuuuuuu\n",
            "Cau da xu ly: em đã rời xa anh...chẳng kịp niúuuuuuuuuuuuuuuu\n",
            "Cau chua xu ly: 4/4/2021 nghe \" đôi mắt \" bỗng nhiên tay lại nổi da gà....nhớ về chàng ca sĩ trẻ tài năng.....\n",
            "Cau da xu ly: 442021 nghe \" đôi mắt \" bỗng nhiên tay lại nổi da gà....nhớ về chàng ca sĩ trẻ tài năng.....\n",
            "Cau chua xu ly: hy vọng sau này tuổi 30 mình sẽ hạnh phúc cùng lkh ❤❤ 28/9/2023 🎉\n",
            "Cau da xu ly: hy vọng sau này tuổi 30 mình sẽ hạnh phúc cùng lkh ❤❤ 2892023 🎉\n",
            "Cau chua xu ly: 4:47 16/06/2020 692 like 0 dislike\n",
            "Cau da xu ly: 4:47 16062020 692 like 0 dislike\n",
            "Cau chua xu ly: 03/7/1989, giờ đã có 2 đứa con và những bài hát này là một thời gian đẹp nhất, viết thư tỏ tình với bạn học, giận hờn vu vơ, giờ thì...\n",
            "Cau da xu ly: 0371989, giờ đã có 2 đứa con và những bài hát này là một thời gian đẹp nhất, viết thư tỏ tình với bạn học, giận hờn vu vơ, giờ thì...\n",
            "Cau chua xu ly: 3/1/2020\n",
            "Cau da xu ly: 312020\n",
            "Cau chua xu ly: thằng ohaha tưởng chỉ cụt tay, hoá ra giờ cụt cả chân, hoà nhập vs gánh xiếc nhanh quá quả thứ 3 icardi nó lỡ đà rồi vẫn đổ người cho nó bấm qua dù khoảng cách ko quá gần, phán đoán tệ vl luôn\n",
            "Cau da xu ly: thằng ohaha tưởng chỉ cụt tay, hóa ra giờ cụt cả chân, hòa nhập vs gánh xiếc nhanh quá quả thứ 3 icardi nó lỡ đà rồi vẫn đổ người cho nó bấm qua dù khoảng cách ko quá gần, phán đoán tệ vl luôn\n",
            "Cau chua xu ly: ai cứu r4 đi qua mỏur đi r4 ơi\n",
            "Cau da xu ly: ai cứu r4 đi qua moủr đi r4 ơi\n",
            "Cau chua xu ly: qúa tuyệt vời cho một list nhạc toàn những bài hay và không quảng cáo <3 cảm ơn kênh vì tất cả ^^\n",
            "Cau da xu ly: quá tuyệt vời cho một list nhạc toàn những bài hay và không quảng cáo <3 cảm ơn kênh vì tất cả ^^\n",
            "Cau chua xu ly: dao hiệu bảo long có bán ở quận 5 tphcm 1 triệu/cây dao y chang trong phim luôn chứ không mắc như phim . còn món ăn thì nhà hàng quận 5 nấu cũng y chang phim luôn .\n",
            "Cau da xu ly: dao hiệu bảo long có bán ở quận 5 tphcm 1 triệucây dao y chang trong phim luôn chứ không mắc như phim . còn món ăn thì nhà hàng quận 5 nấu cũng y chang phim luôn .\n",
            "Cau chua xu ly: hãy thương tui share và like thật nhiềuuu vì sắp tới sẽ có một bất ngờ khác version chill hơn tí xíu cho tất cả các bạn nèeee\n",
            "Cau da xu ly: hãy thương tui share và like thật nhiềuuu vì sắp tới sẽ có một bất ngờ khác version chill hơn tí xíu cho tất cả các bạn neèee\n",
            "Cau chua xu ly: chẳng lẽ em mãi chẳng thuộc về anh à =))) 21/06/2020\n",
            "Cau da xu ly: chẳng lẽ em mãi chẳng thuộc về anh à =))) 21062020\n",
            "Cau chua xu ly: mê lắmmm ạaaaaaa\n",
            "Cau da xu ly: mê lắmmm aạaaaaa\n",
            "Cau chua xu ly: cảm ơn tất cả các bạn đã thích bài hát của mình hãy ủng hộ mình và bài hát này nhiều hơn nữa để có tuôi coá động lực ra bản rnb nghe cực chill luôn nàaa\\\n",
            "Cau da xu ly: cảm ơn tất cả các bạn đã thích bài hát của mình hãy ủng hộ mình và bài hát này nhiều hơn nữa để có tuôi cóa động lực ra bản rnb nghe cực chill luôn naàa\\\n",
            "Cau chua xu ly: khóc cho thoả lòng rồi ngủ thôi\n",
            "Cau da xu ly: khóc cho thỏa lòng rồi ngủ thôi\n",
            "Cau chua xu ly: ae nào biết cách tải những link nhạc như vậy về laptop ko?! chỉ mình nhéeeeeeeeee\n",
            "Cau da xu ly: ae nào biết cách tải những link nhạc như vậy về laptop ko?! chỉ mình nheéeeeeeeee\n",
            "Cau chua xu ly: 24/08/2020\n",
            "Cau da xu ly: 24082020\n",
            "Cau chua xu ly: /12/2020 vẩn hay\n",
            "Cau da xu ly: 122020 vẩn hay\n",
            "Cau chua xu ly: 5/11/2020\n",
            "Cau da xu ly: 5112020\n",
            "Cau chua xu ly: 27/12 đôi mắt buồn\n",
            "Cau da xu ly: 2712 đôi mắt buồn\n",
            "Cau chua xu ly: 2/3.2021\n",
            "Cau da xu ly: 23.2021\n",
            "Cau chua xu ly: mu mùa này họ đã rời vào bảng đấu dễ thở nhất những họ chơi quá tệ và nhạt mơ hoà byen rồi lại để thua một đội bóng tầm trung nữa thật sự là quá tệ\n",
            "Cau da xu ly: mu mùa này họ đã rời vào bảng đấu dễ thở nhất những họ chơi quá tệ và nhạt mơ hòa byen rồi lại để thua một đội bóng tầm trung nữa thật sự là quá tệ\n",
            "Cau chua xu ly: 14/2/2019\n",
            "Cau da xu ly: 1422019\n",
            "Cau chua xu ly: 14/12/2020\n",
            "Cau da xu ly: 14122020\n",
            "Cau chua xu ly: chị nào hát bài giấc mơ tuyết trắng dỡ thật. phải chuyển bài gấp..... nghe chảyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy hết cả nước ra\n",
            "Cau da xu ly: chị nào hát bài giấc mơ tuyết trắng dỡ thật. phải chuyển bài gấp..... nghe chaỷyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy hết cả nước ra\n",
            "Cau chua xu ly: 11/2020 có ai còn nghe không?\n",
            "Cau da xu ly: 112020 có ai còn nghe không?\n",
            "Cau chua xu ly: 12/07/2020 đã ghé thăm. cớ sao up tận 2 năm rồi mà mình mới thấy, thực sự thích nghe những bản nhạc cover ngày xưa hay như này...\n",
            "Cau da xu ly: 12072020 đã ghé thăm. cớ sao up tận 2 năm rồi mà mình mới thấy, thực sự thích nghe những bản nhạc cover ngày xưa hay như này...\n",
            "Cau chua xu ly: 03/01/2021 anh tin mình đã cho nhau một kỉ niệm rồi mãi mãi anh không quên được em!!!\n",
            "Cau da xu ly: 03012021 anh tin mình đã cho nhau một kỉ niệm rồi mãi mãi anh không quên được em!!!\n",
            "Cau chua xu ly: vấn đề k nằm ở mu mà nằm ở đầừ trọc ten hag\n",
            "Cau da xu ly: vấn đề k nằm ở mu mà nằm ở đầư trọc ten hag\n",
            "Cau chua xu ly: 09/09/2020, dù có qua bao nhiêu năm, bao nhiêu bài hát mới ra mắt thì mình vẫn chỉ thích và muốn nghe lại những bài hát đã cũ này!\n",
            "Cau da xu ly: 09092020, dù có qua bao nhiêu năm, bao nhiêu bài hát mới ra mắt thì mình vẫn chỉ thích và muốn nghe lại những bài hát đã cũ này!\n",
            "Cau chua xu ly: 10/4/2020\n",
            "Cau da xu ly: 1042020\n",
            "Cau chua xu ly: nghe bài này thấy nhẹ nhàng, nghe từ lúc cuối năm lớp 12. mà giờ đã sv năm thứ 5 rồi, nhanh thật. 1 năm với nhiều sự kiện quan trọng!23/12/2018\n",
            "Cau da xu ly: nghe bài này thấy nhẹ nhàng, nghe từ lúc cuối năm lớp 12. mà giờ đã sv năm thứ 5 rồi, nhanh thật. 1 năm với nhiều sự kiện quan trọng!23122018\n",
            "Cau chua xu ly: moá đổi một cầu thủ chơi tay hay bằng một cầu thủ chơi chân hay, mà quên mất rằng vị trí thủ môn cần chơi tay hay nhiều hơn! mẹ nhìn ông thủ môn hãm thật,\n",
            "Cau da xu ly: móa đổi một cầu thủ chơi tay hay bằng một cầu thủ chơi chân hay, mà quên mất rằng vị trí thủ môn cần chơi tay hay nhiều hơn! mẹ nhìn ông thủ môn hãm thật,\n",
            "Cau chua xu ly: muốn ronaldo đi chỉ vì sợ cậu ta toả sáng\n",
            "Cau da xu ly: muốn ronaldo đi chỉ vì sợ cậu ta tỏa sáng\n",
            "Cau chua xu ly: 4,2n like, 19 dislike 19/6/2020\n",
            "Cau da xu ly: 4,2n like, 19 dislike 1962020\n",
            "Cau chua xu ly: thằng ku hojlun này đá dc đấy phát triển tốt thì nó còn biến hoá hơn haland ở khả năng kéo bóng và tgia lối chơi\n",
            "Cau da xu ly: thằng ku hojlun này đá dc đấy phát triển tốt thì nó còn biến hóa hơn haland ở khả năng kéo bóng và tgia lối chơi\n",
            "Cau chua xu ly: 7/6/2020\n",
            "Cau da xu ly: 762020\n",
            "Cau chua xu ly: 19/4/2020\n",
            "Cau da xu ly: 1942020\n",
            "Cau chua xu ly: ngô không lên trời xuống biển 72 phép biến hoá không dùng lại dùng ô haha. dùng chân giỏi đó là tôi phải công nhận. nhưng chỉ giỏi dùng chân chuyền bóng cho đối thủ mà thôi\n",
            "Cau da xu ly: ngô không lên trời xuống biển 72 phép biến hóa không dùng lại dùng ô haha. dùng chân giỏi đó là tôi phải công nhận. nhưng chỉ giỏi dùng chân chuyền bóng cho đối thủ mà thôi\n",
            "Cau chua xu ly: 19/2/2023\n",
            "Cau da xu ly: 1922023\n",
            "Cau chua xu ly: siu nhân hoả long kìa ae\n",
            "Cau da xu ly: siu nhân hỏa long kìa ae\n",
            "Cau chua xu ly: dàn hậu vệ và thủ môn mu xuất sắc tặng quà cho đối phương dàn công rút về sao kịp. dù rất thích mu, nhưng tôi đoán mu giải nào cũng chỉ đi 5/10 đoạn đường\n",
            "Cau da xu ly: dàn hậu vệ và thủ môn mu xuất sắc tặng quà cho đối phương dàn công rút về sao kịp. dù rất thích mu, nhưng tôi đoán mu giải nào cũng chỉ đi 510 đoạn đường\n",
            "Cau chua xu ly: 13/10/2020 vẫn hay\n",
            "Cau da xu ly: 13102020 vẫn hay\n",
            "Cau chua xu ly: e=học/₫\n",
            "Cau da xu ly: e=học₫\n",
            "Cau chua xu ly: clip nhu cai lol, am luong giam han xuong 1/3\n",
            "Cau da xu ly: clip nhu cai lol, am luong giam han xuong 13\n",
            "Cau chua xu ly: cho em xin hợp âm với ạaaaaa\n",
            "Cau da xu ly: cho em xin hợp âm với aạaaaa\n",
            "Cau chua xu ly: 2/3/2021 còn nghe..\n",
            "Cau da xu ly: 232021 còn nghe..\n",
            "Cau chua xu ly: 16/04/2021.\n",
            "Cau da xu ly: 16042021.\n",
            "Cau chua xu ly: thảm hoạ onanaa tuyệt cmn vời\n",
            "Cau da xu ly: thảm họa onanaa tuyệt cmn vời\n",
            "Cau chua xu ly: 18/02/2021\n",
            "Cau da xu ly: 18022021\n",
            "Cau chua xu ly: 16/6 nay sinh nhật tui nè , cũng mới chia tay xong !!! mọi người chúc tôi đi :))\n",
            "Cau da xu ly: 166 nay sinh nhật tui nè , cũng mới chia tay xong !!! mọi người chúc tôi đi :))\n",
            "Cau chua xu ly: 31/3.2020 nghe lại\n",
            "Cau da xu ly: 313.2020 nghe lại\n",
            "Cau chua xu ly: anh ten nói, khi trong đội có 10 người chỉ dùng chân, tôi sẽ biến cả đội hoà tan và đoàn kết nhất có thể bằng cách để thủ môn dần quên 1 điều rằng: anh ta có thể dùng tay chơi bóng :))\n",
            "Cau da xu ly: anh ten nói, khi trong đội có 10 người chỉ dùng chân, tôi sẽ biến cả đội hòa tan và đoàn kết nhất có thể bằng cách để thủ môn dần quên 1 điều rằng: anh ta có thể dùng tay chơi bóng :))\n",
            "Cau chua xu ly: 27/9/2019\n",
            "Cau da xu ly: 2792019\n",
            "Cau chua xu ly: sau chia tay ai cũng khác, tìm một ngừoi mới sau vỡ nát. hay quá anh ơi. em thích nghe nhạc của anh lắm.\n",
            "Cau da xu ly: sau chia tay ai cũng khác, tìm một ngưòi mới sau vỡ nát. hay quá anh ơi. em thích nghe nhạc của anh lắm.\n",
            "Cau chua xu ly: mọi người đăng ký kênh giúp mình với cám ơn mn! https://www.youtube.com/channel/ucq11lrio-cwcinfz4astnoq\n",
            "Cau da xu ly: mọi người đăng ký kênh giúp mình với cám ơn mn! https:www.youtube.comchannelucq11lrio-cwcinfz4astnoq\n",
            "Cau chua xu ly: cám ơn. onana dất nhiều.đặc vụ được phải đến để huỷ diệt tenhag\n",
            "Cau da xu ly: cám ơn. onana dất nhiều.đặc vụ được phải đến để hủy diệt tenhag\n",
            "Cau chua xu ly: amrabat đá hay thế nhờ , tiền kiến tạo cho đội bạn ghi bàn luôn haha. quá cháyyyy\n",
            "Cau da xu ly: amrabat đá hay thế nhờ , tiền kiến tạo cho đội bạn ghi bàn luôn haha. quá chaýyyy\n",
            "Cau chua xu ly: nhìn nó đá mà tức ói máuuu\n",
            "Cau da xu ly: nhìn nó đá mà tức ói maúuu\n",
            "Cau chua xu ly: kênh này đã tha hoá, nó bán rẻ cho đồng tiền. muốn làm nô lệ cho đồng tiền nhưng cứ nhân danh vì tính nghệ thuật giải trí, t khinh đạo đức giả :)))\n",
            "Cau da xu ly: kênh này đã tha hóa, nó bán rẻ cho đồng tiền. muốn làm nô lệ cho đồng tiền nhưng cứ nhân danh vì tính nghệ thuật giải trí, t khinh đạo đức giả :)))\n",
            "Cau chua xu ly: đã xem phim đất rừng phương nam. ncl cũng được nhưng chỉ 4/10 của bản gốc thôi\n",
            "Cau da xu ly: đã xem phim đất rừng phương nam. ncl cũng được nhưng chỉ 410 của bản gốc thôi\n",
            "Cau chua xu ly: rác thật sự , này đúng mấy ng tò mò đi xem hoặc ko có film gì thì xem, chứ chán phèo :d 1/10\n",
            "Cau da xu ly: rác thật sự , này đúng mấy ng tò mò đi xem hoặc ko có film gì thì xem, chứ chán phèo :d 110\n",
            "Cau chua xu ly: nếu nhìn về góc độ văn hoá thì đây là một chất độc.\n",
            "Cau da xu ly: nếu nhìn về góc độ văn hóa thì đây là một chất độc.\n",
            "Cau chua xu ly: phim cringe bỏ miẹ\n",
            "Cau da xu ly: phim cringe bỏ mịe\n",
            "Cau chua xu ly: bá dơ xâm trổ gặp đặp đũy thoả l thúi,hợp hợp\n",
            "Cau da xu ly: bá dơ xâm trổ gặp đặp đũy thỏa l thúi,hợp hợp\n",
            "Cau chua xu ly: cách giải quyết mọi vụ việc của công trần ; luôn dĩ hoà vi quý; thấu tình người ! rất trân quý tính cách của em ! rất thẳng thắn !\n",
            "Cau da xu ly: cách giải quyết mọi vụ việc của công trần ; luôn dĩ hòa vi quý; thấu tình người ! rất trân quý tính cách của em ! rất thẳng thắn !\n",
            "Cau chua xu ly: con qủy cái thấy gớm!cho hk thèm\n",
            "Cau da xu ly: con quỷ cái thấy gớm!cho hk thèm\n",
            "Cau chua xu ly: mẹeeeeeeee nó phim dở vcl\n",
            "Cau da xu ly: meẹeeeeeee nó phim dở vcl\n",
            "Cau chua xu ly: cuốn vãi òoooooooooooo\n",
            "Cau da xu ly: cuốn vãi oòooooooooooo\n",
            "Cau chua xu ly: chòi oii đẹp trzai quáaaa\n",
            "Cau da xu ly: chòi oii đẹp trzai quaáaa\n",
            "Cau chua xu ly: cuốn vãiii\n",
            "Cau da xu ly: cuốn vaĩii\n",
            "Cau chua xu ly: qúa tuyệt vời\n",
            "Cau da xu ly: quá tuyệt vời\n",
            "Cau chua xu ly: cuốn vãiii hay quá\n",
            "Cau da xu ly: cuốn vaĩii hay quá\n",
            "Cau chua xu ly: 1000000000/10 điểm excellent\n",
            "Cau da xu ly: 100000000010 điểm excellent\n",
            "Cau chua xu ly: ngầu quáaa mê chị minh anh gê\n",
            "Cau da xu ly: ngầu quaáa mê chị minh anh gê\n",
            "Cau chua xu ly: xinh mà còn giỏii\n",
            "Cau da xu ly: xinh mà còn gioỉi\n",
            "Cau chua xu ly: nghe em này hùng biện mà thấy buồn, một thế hệ chỉ biết đỗ lỗi cho người khác đã bắt đầu lớn lên./.\n",
            "Cau da xu ly: nghe em này hùng biện mà thấy buồn, một thế hệ chỉ biết đỗ lỗi cho người khác đã bắt đầu lớn lên..\n",
            "Cau chua xu ly: -cười lao xuống sông- làm rất đúng chất phim thảm hoạ, ý t bộ phim là thảm hoạ của nền điện ảnh\n",
            "Cau da xu ly: -cười lao xuống sông- làm rất đúng chất phim thảm họa, ý t bộ phim là thảm họa của nền điện ảnh\n",
            "Cau chua xu ly: mình thấy hoá trang và kỹ xảo chưa đạt vì phim zombie dựa nhiều vào 2 thứ trên =))) diễn xuất cũng nửa vời =))) chê\n",
            "Cau da xu ly: mình thấy hóa trang và kỹ xảo chưa đạt vì phim zombie dựa nhiều vào 2 thứ trên =))) diễn xuất cũng nửa vời =))) chê\n",
            "Cau chua xu ly: thảm hoạ nền điện ảnh nước nhà nói riêng và thế giới nói chung :))\n",
            "Cau da xu ly: thảm họa nền điện ảnh nước nhà nói riêng và thế giới nói chung :))\n",
            "Cau chua xu ly: xem rồi phí tiền ích :)))) moá\n",
            "Cau da xu ly: xem rồi phí tiền ích :)))) móa\n",
            "Cau chua xu ly: tầm này thì đi làm phim truyền hình đi chứ có phim điện ảnh nào của việt nam hay đâu :/\n",
            "Cau da xu ly: tầm này thì đi làm phim truyền hình đi chứ có phim điện ảnh nào của việt nam hay đâu :\n",
            "Cau chua xu ly: phim người việt thường khá tệ còn phim này thì là thất bại của tạo hoá chê đi\n",
            "Cau da xu ly: phim người việt thường khá tệ còn phim này thì là thất bại của tạo hóa chê đi\n",
            "Cau chua xu ly: phim vn là phim hay nhất tg ai cãi lại chê phim vn là 3/\n",
            "Cau da xu ly: phim vn là phim hay nhất tg ai cãi lại chê phim vn là 3\n",
            "Cau chua xu ly: bài hay waa tr lun íiii 🤯\n",
            "Cau da xu ly: bài hay waa tr lun iíii 🤯\n",
            "Cau chua xu ly: hay quaas w/n ơi\n",
            "Cau da xu ly: hay quaas wn ơi\n",
            "Cau chua xu ly: tớ rất thích bài hát này. thực sự là nó đã đồng hành cùng tớ và anh tớ suốt thời thanh xuân, nghe bài hát ấy. tớ cảm thấy như mk ko còn bị bỏ rơi, ko bị bạo lực học đường như ngày xưa nx. cảm ơn w /n rất nhiều nhé! (>3<) ありがとう\n",
            "Cau da xu ly: tớ rất thích bài hát này. thực sự là nó đã đồng hành cùng tớ và anh tớ suốt thời thanh xuân, nghe bài hát ấy. tớ cảm thấy như mk ko còn bị bỏ rơi, ko bị bạo lực học đường như ngày xưa nx. cảm ơn w n rất nhiều nhé! (>3<) ありがとう\n",
            "Cau chua xu ly: nghe rat chill cam on w/n ❤\n",
            "Cau da xu ly: nghe rat chill cam on wn ❤\n",
            "Cau chua xu ly: e xin lời của đoạn đầu để cover ạ 💗 hay quáaa\n",
            "Cau da xu ly: e xin lời của đoạn đầu để cover ạ 💗 hay quaáa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BgffCFZe8ka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "48ad37c0-3716-410e-fc03-0b6985f478b3"
      },
      "source": [
        "text = u'This is a smiley face 😂'\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a smiley face 😂'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFnYCXtDM7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42c05af-a400-4776-8301-a3fe9aabcef8"
      },
      "source": [
        "!pip install spacymoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacymoji\n",
            "  Downloading spacymoji-3.1.0-py2.py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from spacymoji) (3.6.1)\n",
            "Collecting emoji<3.0,>=2.0 (from spacymoji)\n",
            "  Downloading emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.5/397.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacymoji) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacymoji) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacymoji) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacymoji) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacymoji) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacymoji) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.0.0->spacymoji) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.0.0->spacymoji) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacymoji) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacymoji) (2.1.3)\n",
            "Installing collected packages: emoji, spacymoji\n",
            "Successfully installed emoji-2.9.0 spacymoji-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPj5H-HXN5ht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fc640a-1e61-4468-ea73-45c1a8bc225c"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-24 03:12:49.645840: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-24 03:12:49.645911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-24 03:12:49.660501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-24 03:12:49.689317: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-24 03:12:52.898578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Owkp-ZNMq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34ed9ab-d0f6-4d5f-c198-f179f33aaf9f"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "from spacymoji import Emoji\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "emoji = Emoji(nlp)\n",
        "nlp.add_pipe('emoji', first=True)\n",
        "\n",
        "doc = nlp(\"sale hay sela :))\")\n",
        "print([token.text for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sale', 'hay', 'sela', ':))']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8AljlN8R4F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9348e8-fbde-4932-fe58-41d3a26eb59a"
      },
      "source": [
        "doc = nlp(\"sale hay sela 😂 thật vãi lồn ha\")\n",
        "print([token.text for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sale', 'hay', 'sela', '😂', 'thật', 'vãi', 'lồn', 'ha']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpooafddW_s0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d1cbcc-eea9-4de2-8495-4071ac71dbda"
      },
      "source": [
        "doc[3]._.is_emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vncorenlp"
      ],
      "metadata": {
        "id": "mzd8neE8Jejx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce7fd0d-53aa-4cc1-f78b-488795296caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vncorenlp\n",
            "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vncorenlp) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2023.11.17)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645932 sha256=00f3103b9bde171ab062a50d1f6df95ea06d0013ec7a7765a69bd75ca1f34681\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/d9/b3/41f6c6b1ab758561fd4aab55dc0480b9d7a131c6aaa573a3fa\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvqmOXGZPd2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58acac23-9268-441a-d350-f475ca5e5193"
      },
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "rdrsegmenter = VnCoreNLP(\"/content/drive/MyDrive/VnCoreNLP-1.2/VnCoreNLP-1.2/VnCoreNLP-1.2.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "word_segmented_text = rdrsegmenter.tokenize(\"sale hay sela :D thật vãi lồn ha 😂😂😂😂😂\")\n",
        "word_segmented_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['sale', 'hay', 'sela', ':', 'D', 'thật', 'vãi', 'lồn', 'ha', '😂😂😂😂😂']]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK7GdrRkT3yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513a21b6-3190-4c01-9471-a4169d79d981"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting demoji\n",
            "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: demoji\n",
            "Successfully installed demoji-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdLqiFAjTqN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea11e466-ecb3-4504-f33d-1ec59b8bfa8d"
      },
      "source": [
        "import demoji\n",
        "demoji.download_codes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-eb011a9810ad>:2: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
            "  demoji.download_codes()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsncdHBOUFSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "276a4a53-8bbf-4ffb-cf43-402d39204943"
      },
      "source": [
        "text = \"sale hay sela :)))))))))))))) thật vãi lồn ha\"\n",
        "re.sub(r'([A-Z])\\1+', lambda m: m.group(1), text, flags = re.IGNORECASE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sale hay sela :)))))))))))))) thật vãi lồn ha'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4QrjEo4U86u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7a9f58-4ced-4e14-dc49-cc1c296699ae"
      },
      "source": [
        "demoji.findall(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea\n",
        "\n",
        "from underthesea import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHwc7L9PyhlA",
        "outputId": "cf4865d0-e40c-4684-ed52-2221ae894c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.0-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2023.11.17)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.2.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.10 underthesea-6.8.0 underthesea-core-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "teencode_df = pd.read_csv('/content/drive/MyDrive/Textual data/teencode.txt',names=['teencode','map'],sep='\\t',)\n",
        "teencode_list = teencode_df['teencode'].to_list()\n",
        "map_list = teencode_df['map'].to_list()\n",
        "def searchTeencode(word):\n",
        "  try:\n",
        "    global teencode_count\n",
        "    index = teencode_list.index(word)\n",
        "    map_word = map_list[index]\n",
        "    teencode_count += 1\n",
        "    return map_word\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "rM4anXW0yiBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STOPWORDS = '/content/drive/MyDrive/Textual data/vietnamese-stopwords-dash.txt'\n",
        "\n",
        "# features extraction\n",
        "with open(STOPWORDS, \"r\") as ins:\n",
        "    stopword = []\n",
        "    for line in ins:\n",
        "        stopword.append(line.strip('\\n'))\n",
        "\n",
        "def remove_stopwords(line):\n",
        "    global stopword_count\n",
        "    words = []\n",
        "    for word in line.strip().split():\n",
        "        if word not in stopword:\n",
        "            words.append(word)\n",
        "        if word in stopword:\n",
        "            stopword_count += 1\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "sQSiqaSbysBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopword_count = 0\n",
        "teencode_count =0\n",
        "def stopWords_Teencode(sentence):\n",
        "  lenn = 0\n",
        "  sentence = str(sentence)\n",
        "  #Tokenize\n",
        "  List_tokens = word_tokenize(sentence,format='text')\n",
        "  List_tokens = word_tokenize(List_tokens)\n",
        "\n",
        "  #Teencode\n",
        "  for tokens_idx, text_tokens in enumerate(List_tokens):\n",
        "    deteencoded = searchTeencode(text_tokens)\n",
        "    if (deteencoded != None):\n",
        "        List_tokens[tokens_idx] = deteencoded\n",
        "\n",
        "  deteencode_sentence = (\" \").join(List_tokens)\n",
        "\n",
        "  #Stopwords\n",
        "  tokens_without_sw = remove_stopwords(deteencode_sentence)\n",
        "\n",
        "  return tokens_without_sw"
      ],
      "metadata": {
        "id": "GQ62MKIJyw4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopword_count = 0\n",
        "teencode_count =0\n",
        "train['vi_review'] = train['vi_review'].apply(lambda x:stopWords_Teencode(x))"
      ],
      "metadata": {
        "id": "aD6OpA2RzoY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF__6Sobo7tz"
      },
      "source": [
        "# EXPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbfP4n2rhP37"
      },
      "source": [
        "train.to_csv('/content/drive/MyDrive/siu.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}